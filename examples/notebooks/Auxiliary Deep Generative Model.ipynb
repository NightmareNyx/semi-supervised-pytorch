{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Deep Generative Model\n",
    "\n",
    "The Auxiliary Deep Generative Model [[Maal√∏e, 2016]](https://arxiv.org/abs/1602.05473) posits a model that with an auxiliary latent variable $a$ that infers the variables $z$ and $y$. This helps in terms of semi-supervised learning by delegating causality to their respective variables. This model was state-of-the-art in semi-supervised until 2017, and is still very powerful with an MNIST accuracy of *99.4%* using just 10 labelled examples per class.\n",
    "\n",
    "<img src=\"../images/adgm.png\" width=\"400px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuxiliaryDeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=826, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (log_var): Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=816, out_features=256, bias=True)\n",
       "    (logits): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       "  (aux_encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (log_var): Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (aux_decoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=826, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (log_var): Linear(in_features=256, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import AuxiliaryDeepGenerativeModel\n",
    "\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "a_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "model = AuxiliaryDeepGenerativeModel([784, y_dim, z_dim, a_dim, h_dim])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The lower bound we derived in the notebook for the **deep generative model** is similar to the one for the ADGM. Here, we also need to integrate over a continuous auxiliary variable $a$.\n",
    "\n",
    "For labelled data, the lower bound is given by.\n",
    "\\begin{align}\n",
    "\\log p(x,y) &= \\log \\int \\int p(x, y, a, z) \\ dz \\ da\\\\\n",
    "&\\geq \\mathbb{E}_{q(a,z|x,y)} \\bigg [\\log \\frac{p(x,y,a,z)}{q(a,z|x,y)} \\bigg ] = - \\mathcal{L}(x,y)\n",
    "\\end{align}\n",
    "\n",
    "Again when no label information is available we sum out all of the labels.\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x) &= \\log \\int \\sum_{y} \\int p(x, y, a, z) \\ dz \\ da\\\\\n",
    "&\\geq \\mathbb{E}_{q(a,y,z|x)} \\bigg [\\log \\frac{p(x,y,a,z)}{q(a,y,z |x)} \\bigg ] = - \\mathcal{U}(x)\n",
    "\\end{align}\n",
    "\n",
    "Where we decompose the q-distribution into its constituent parts. $q(a, y, z|x) = q(z|a,y,x)q(y|a,x)q(a|x)$, which is also what can be seen in the figure.\n",
    "\n",
    "The distribution over $a$ is similar to $z$ in the sense that it is also a diagonal Gaussian distribution. However by introducing the auxiliary variable we allow for $z$ to become arbitrarily complex - something we can also see when using normalizing flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nightmare/miniconda3/envs/intel/lib/python3.6/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nightmare/miniconda3/envs/intel/lib/python3.6/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from datautils import get_mnist\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, validation = get_mnist(location=\"./\", batch_size=64, labels_per_class=10)\n",
    "alpha = 0.1 * (len(unlabelled) + len(labelled)) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, DeterministicWarmup\n",
    "\n",
    "# We will need to use warm-up in order to achieve good performance.\n",
    "# Over 200 calls to SVI we change the autoencoder from\n",
    "# deterministic to stochastic.\n",
    "beta = DeterministicWarmup(n=200)\n",
    "\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is conventially packed with the `SVI` method that does all of the work of calculating the lower bound for both labelled and unlabelled data depending on whether the label is given. It also manages to perform the enumeration of all the labels.\n",
    "\n",
    "Remember that the labels have to be in a *one-hot encoded* format in order to work with SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(547.0621, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(544.2576, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(540.6196, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(538.0085, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(534.1075, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(531.1522, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(526.4666, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(523.5862, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(520.0656, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(515.6301, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(509.3595, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(506.2549, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(499.8593, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(495.1693, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(489.8462, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(478.9657, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(473.2193, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(460.7838, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(452.8986, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(442.4664, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(433.0064, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(415.2522, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(403.0435, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(390.6711, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(372.7820, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(355.4371, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(337.6601, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(320.1604, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(317.0229, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(306.3360, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(303.4971, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(299.4262, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(299.2711, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(285.6828, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(287.1366, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(275.0003, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(271.6319, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(262.5081, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(258.2448, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(254.4423, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(251.7870, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(249.4748, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(246.4071, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(245.8184, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(240.2168, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(245.6037, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(243.4059, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(239.2664, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(237.9922, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(237.0186, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(234.9880, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([36])\n",
      "elbo after torch.Size([36])\n",
      "tensor(236.9108, grad_fn=<NegBackward>)\n",
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n",
      "elbo before torch.Size([64])\n",
      "elbo after torch.Size([64])\n",
      "tensor(231.4938, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo before torch.Size([640])\n",
      "elbo after torch.Size([640])\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36m_serve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got end of file during message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9ab82b7d6662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/intel/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/semi-supervised-pytorch/semi-supervised/inference/variational.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Increase sampling dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/semi-supervised-pytorch/semi-supervised/inference/variational.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresample_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        print(L)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.item()\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data[0]\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional generation\n",
    "\n",
    "When the model is done training you can generate samples conditionally given some normal distributed noise $z$ and a label $y$.\n",
    "\n",
    "*The model below has only trained for 10 iterations, so the perfomance is not representative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import onehot\n",
    "model.eval()\n",
    "\n",
    "z = Variable(torch.randn(16, 32))\n",
    "\n",
    "# Generate a batch of 5s\n",
    "y = Variable(onehot(10)(5).repeat(16, 1))\n",
    "\n",
    "x_mu = model.sample(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 16, figsize=(18, 12))\n",
    "\n",
    "samples = x_mu.data.view(-1, 28, 28).numpy()\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(samples[i])\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = torch.Tensor(np.array([[0,1,2,3,4,5],[8,9,10,11,12,0],[21,22,21,0,0,0]]))\n",
    "array_len = torch.Tensor([6,5,3])\n",
    "\n",
    "m = ~(torch.ones(array_2d.size()).cumsum(dim=1).t() > array_len).t()\n",
    "array_2d[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(lengths, maxlen, dtype=torch.bool):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    mask = ~(torch.ones((len(lengths), maxlen)).cumsum(dim=1).t() > lengths).t()\n",
    "    mask.type(dtype)\n",
    "    return mask\n",
    "\n",
    "sequence_mask(array_len, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_poisson_loss(targets, log_input, compute_full_loss=False):\n",
    "    \"\"\"Computes log Poisson loss given `log_input`.\n",
    "    Gives the log-likelihood loss between the prediction and the target under the\n",
    "    assumption that the target has a Poisson distribution.\n",
    "    Caveat: By default, this is not the exact loss, but the loss minus a\n",
    "    constant term [log(z!)]. That has no effect for optimization, but\n",
    "    does not play well with relative loss comparisons. To compute an\n",
    "    approximation of the log factorial term, specify\n",
    "    compute_full_loss=True to enable Stirling's Approximation.\n",
    "    For brevity, let `c = log(x) = log_input`, `z = targets`.  The log Poisson\n",
    "    loss is\n",
    "        -log(exp(-x) * (x^z) / z!)\n",
    "      = -log(exp(-x) * (x^z)) + log(z!)\n",
    "      ~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n",
    "          [ Note the second term is the Stirling's Approximation for log(z!).\n",
    "            It is invariant to x and does not affect optimization, though\n",
    "            important for correct relative loss comparisons. It is only\n",
    "            computed when compute_full_loss == True. ]\n",
    "      = x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n",
    "      = exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n",
    "    Args:\n",
    "    targets: A `Tensor` of the same type and shape as `log_input`.\n",
    "    log_input: A `Tensor` of type `float32` or `float64`.\n",
    "    compute_full_loss: whether to compute the full loss. If false, a constant\n",
    "      term is dropped in favor of more efficient optimization.\n",
    "    name: A name for the operation (optional).\n",
    "    Returns:\n",
    "    A `Tensor` of the same shape as `log_input` with the componentwise\n",
    "    logistic losses.\n",
    "    Raises:\n",
    "    ValueError: If `log_input` and `targets` do not have the same shape.\n",
    "    \"\"\"\n",
    "    if targets.size() != log_input.size():\n",
    "        raise ValueError(\n",
    "            \"log_input and targets must have the same shape (%s vs %s)\" %\n",
    "            (log_input.size(), targets.size()))\n",
    "\n",
    "    result = torch.exp(log_input) - log_input * targets\n",
    "    if compute_full_loss:\n",
    "        # need to create constant tensors here so that their dtypes can be matched\n",
    "        # to that of the targets.\n",
    "        point_five = 0.5  # constant_op.constant(0.5, dtype=targets.dtype)\n",
    "        two_pi = 2 * math.pi  # constant_op.constant(2 * math.pi, dtype=targets.dtype)\n",
    "\n",
    "        stirling_approx = (targets * torch.log(targets)) - targets + (\n",
    "                point_five * torch.log(two_pi * targets))\n",
    "        zeros = torch.zeros_like(targets, dtype=targets.dtype)\n",
    "        ones = torch.ones_like(targets, dtype=targets.dtype)\n",
    "        cond = (targets >= zeros) & (targets <= ones)  # math_ops.logical_and(targets >= zeros, targets <= ones)\n",
    "        result += torch.where(cond, zeros, stirling_approx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.Tensor([[1,2,3,4], [5,6,7,8]])\n",
    "log_input = torch.Tensor([[2,3,4,5,5], [6,7,8,9,5]])\n",
    "log_poisson_loss(targets, log_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.log_poisson_loss(targets.numpy(), log_input.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(6,4) + np.random.uniform(6,4) + np.random.gamma(6,4) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.mean(), A.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ap = torch.Tensor(A)\n",
    "At = tf.convert_to_tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.BatchNorm1d(4)(Ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = tf.nn.moments(At, 0)\n",
    "tf.nn.batch_normalization(At, m, v, offset=0.0, scale=1.0, variance_epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
